{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "619Fcv2Zoe3h"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "novoArray = np.random.rand(5,5)\n",
        "print(novoArray)\n",
        "print(type(novoArray))"
      ],
      "metadata": {
        "id": "wHQKnJfVoqb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff1e6223-7dd8-4d14-fde2-9ef5f21b5d0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.34665161 0.43823835 0.7476897  0.38586166 0.26841529]\n",
            " [0.52855441 0.86271072 0.08065284 0.36186815 0.96816339]\n",
            " [0.78961209 0.43026309 0.44912314 0.39254216 0.96219331]\n",
            " [0.47909411 0.63953919 0.70014646 0.9745922  0.08426539]\n",
            " [0.71908238 0.94361413 0.49038168 0.40149322 0.37351599]]\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tensor vs Array\n",
        "novoTensor = torch.rand(5,5)\n",
        "print(novoTensor) \n",
        "print(type(novoTensor)) \n",
        "print(novoArray)\n",
        "print(type(novoArray))"
      ],
      "metadata": {
        "id": "OMfvca8joqeq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0c27d9b-8f88-41ad-db23-44ac70d64198"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0746, 0.3838, 0.8470, 0.3879, 0.1461],\n",
            "        [0.4231, 0.3021, 0.5083, 0.3329, 0.1262],\n",
            "        [0.0708, 0.7117, 0.7834, 0.7299, 0.0509],\n",
            "        [0.3233, 0.9016, 0.2817, 0.1189, 0.3678],\n",
            "        [0.1330, 0.7702, 0.4272, 0.2434, 0.9628]])\n",
            "<class 'torch.Tensor'>\n",
            "[[0.34665161 0.43823835 0.7476897  0.38586166 0.26841529]\n",
            " [0.52855441 0.86271072 0.08065284 0.36186815 0.96816339]\n",
            " [0.78961209 0.43026309 0.44912314 0.39254216 0.96219331]\n",
            " [0.47909411 0.63953919 0.70014646 0.9745922  0.08426539]\n",
            " [0.71908238 0.94361413 0.49038168 0.40149322 0.37351599]]\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar um modelo de Rede Neural\n",
        "class Net(torch.nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(Net, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size) #full connected\n",
        "    self.relu = torch.nn.ReLU() #(0, infinito)\n",
        "    self.fc2 = torch.nn.Linear(self.hidden_size, 1)\n",
        "    self.sigmoid = torch.nn.Sigmoid() #(0, 1)\n",
        "  def forward(self, x):\n",
        "    hidden = self.fc1(x)\n",
        "    relu = self.relu(hidden)\n",
        "    output = self.fc2(relu)\n",
        "    output = self.sigmoid(output)\n",
        "    return output"
      ],
      "metadata": {
        "id": "VOJvDjlPouuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()\n",
        "# data, target, target_names\n",
        "# print(iris)\n",
        "dados = iris.data\n",
        "classes = iris.target\n",
        "nomesClasses = iris.target_names"
      ],
      "metadata": {
        "id": "uT9VwYqrozrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converter as classes\n",
        "print(classes)\n",
        "print(nomesClasses)\n",
        "import numpy as np\n",
        "# saida = np.where(condição, true, false)\n",
        "# saida = np.where(classes==2, 1, 0) # virginica\n",
        "saida = np.where(classes== 2, 1, 0)\n",
        "print(saida)\n",
        "# 0: setosa; 1: versicolor; 2: virginica;\n",
        "# 0: setosa; 0: versicolor; 1: virginica;"
      ],
      "metadata": {
        "id": "cEAonZ4go0ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "971e8b28-2cd0-4bbf-f1ae-80167d3f0312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n",
            "['setosa' 'versicolor' 'virginica']\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Converter para tensor\n",
        "entrada = torch.FloatTensor(dados) / 10\n",
        "saida = torch.FloatTensor(saida)\n",
        "print(torch.max(entrada))\n",
        "print(saida)"
      ],
      "metadata": {
        "id": "A-Uvv_piqJwZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2c78593-7e55-4cc2-e82f-a5b83d9d8a64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7900)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "print(entrada, saida)\n",
        "entrada, saida = shuffle(entrada, saida)\n",
        "print(entrada, saida)"
      ],
      "metadata": {
        "id": "ojUIQTmkqKuQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9509f04c-c004-46ef-ab35-df5f387ef433"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5100, 0.3500, 0.1400, 0.0200],\n",
            "        [0.4900, 0.3000, 0.1400, 0.0200],\n",
            "        [0.4700, 0.3200, 0.1300, 0.0200],\n",
            "        [0.4600, 0.3100, 0.1500, 0.0200],\n",
            "        [0.5000, 0.3600, 0.1400, 0.0200],\n",
            "        [0.5400, 0.3900, 0.1700, 0.0400],\n",
            "        [0.4600, 0.3400, 0.1400, 0.0300],\n",
            "        [0.5000, 0.3400, 0.1500, 0.0200],\n",
            "        [0.4400, 0.2900, 0.1400, 0.0200],\n",
            "        [0.4900, 0.3100, 0.1500, 0.0100],\n",
            "        [0.5400, 0.3700, 0.1500, 0.0200],\n",
            "        [0.4800, 0.3400, 0.1600, 0.0200],\n",
            "        [0.4800, 0.3000, 0.1400, 0.0100],\n",
            "        [0.4300, 0.3000, 0.1100, 0.0100],\n",
            "        [0.5800, 0.4000, 0.1200, 0.0200],\n",
            "        [0.5700, 0.4400, 0.1500, 0.0400],\n",
            "        [0.5400, 0.3900, 0.1300, 0.0400],\n",
            "        [0.5100, 0.3500, 0.1400, 0.0300],\n",
            "        [0.5700, 0.3800, 0.1700, 0.0300],\n",
            "        [0.5100, 0.3800, 0.1500, 0.0300],\n",
            "        [0.5400, 0.3400, 0.1700, 0.0200],\n",
            "        [0.5100, 0.3700, 0.1500, 0.0400],\n",
            "        [0.4600, 0.3600, 0.1000, 0.0200],\n",
            "        [0.5100, 0.3300, 0.1700, 0.0500],\n",
            "        [0.4800, 0.3400, 0.1900, 0.0200],\n",
            "        [0.5000, 0.3000, 0.1600, 0.0200],\n",
            "        [0.5000, 0.3400, 0.1600, 0.0400],\n",
            "        [0.5200, 0.3500, 0.1500, 0.0200],\n",
            "        [0.5200, 0.3400, 0.1400, 0.0200],\n",
            "        [0.4700, 0.3200, 0.1600, 0.0200],\n",
            "        [0.4800, 0.3100, 0.1600, 0.0200],\n",
            "        [0.5400, 0.3400, 0.1500, 0.0400],\n",
            "        [0.5200, 0.4100, 0.1500, 0.0100],\n",
            "        [0.5500, 0.4200, 0.1400, 0.0200],\n",
            "        [0.4900, 0.3100, 0.1500, 0.0200],\n",
            "        [0.5000, 0.3200, 0.1200, 0.0200],\n",
            "        [0.5500, 0.3500, 0.1300, 0.0200],\n",
            "        [0.4900, 0.3600, 0.1400, 0.0100],\n",
            "        [0.4400, 0.3000, 0.1300, 0.0200],\n",
            "        [0.5100, 0.3400, 0.1500, 0.0200],\n",
            "        [0.5000, 0.3500, 0.1300, 0.0300],\n",
            "        [0.4500, 0.2300, 0.1300, 0.0300],\n",
            "        [0.4400, 0.3200, 0.1300, 0.0200],\n",
            "        [0.5000, 0.3500, 0.1600, 0.0600],\n",
            "        [0.5100, 0.3800, 0.1900, 0.0400],\n",
            "        [0.4800, 0.3000, 0.1400, 0.0300],\n",
            "        [0.5100, 0.3800, 0.1600, 0.0200],\n",
            "        [0.4600, 0.3200, 0.1400, 0.0200],\n",
            "        [0.5300, 0.3700, 0.1500, 0.0200],\n",
            "        [0.5000, 0.3300, 0.1400, 0.0200],\n",
            "        [0.7000, 0.3200, 0.4700, 0.1400],\n",
            "        [0.6400, 0.3200, 0.4500, 0.1500],\n",
            "        [0.6900, 0.3100, 0.4900, 0.1500],\n",
            "        [0.5500, 0.2300, 0.4000, 0.1300],\n",
            "        [0.6500, 0.2800, 0.4600, 0.1500],\n",
            "        [0.5700, 0.2800, 0.4500, 0.1300],\n",
            "        [0.6300, 0.3300, 0.4700, 0.1600],\n",
            "        [0.4900, 0.2400, 0.3300, 0.1000],\n",
            "        [0.6600, 0.2900, 0.4600, 0.1300],\n",
            "        [0.5200, 0.2700, 0.3900, 0.1400],\n",
            "        [0.5000, 0.2000, 0.3500, 0.1000],\n",
            "        [0.5900, 0.3000, 0.4200, 0.1500],\n",
            "        [0.6000, 0.2200, 0.4000, 0.1000],\n",
            "        [0.6100, 0.2900, 0.4700, 0.1400],\n",
            "        [0.5600, 0.2900, 0.3600, 0.1300],\n",
            "        [0.6700, 0.3100, 0.4400, 0.1400],\n",
            "        [0.5600, 0.3000, 0.4500, 0.1500],\n",
            "        [0.5800, 0.2700, 0.4100, 0.1000],\n",
            "        [0.6200, 0.2200, 0.4500, 0.1500],\n",
            "        [0.5600, 0.2500, 0.3900, 0.1100],\n",
            "        [0.5900, 0.3200, 0.4800, 0.1800],\n",
            "        [0.6100, 0.2800, 0.4000, 0.1300],\n",
            "        [0.6300, 0.2500, 0.4900, 0.1500],\n",
            "        [0.6100, 0.2800, 0.4700, 0.1200],\n",
            "        [0.6400, 0.2900, 0.4300, 0.1300],\n",
            "        [0.6600, 0.3000, 0.4400, 0.1400],\n",
            "        [0.6800, 0.2800, 0.4800, 0.1400],\n",
            "        [0.6700, 0.3000, 0.5000, 0.1700],\n",
            "        [0.6000, 0.2900, 0.4500, 0.1500],\n",
            "        [0.5700, 0.2600, 0.3500, 0.1000],\n",
            "        [0.5500, 0.2400, 0.3800, 0.1100],\n",
            "        [0.5500, 0.2400, 0.3700, 0.1000],\n",
            "        [0.5800, 0.2700, 0.3900, 0.1200],\n",
            "        [0.6000, 0.2700, 0.5100, 0.1600],\n",
            "        [0.5400, 0.3000, 0.4500, 0.1500],\n",
            "        [0.6000, 0.3400, 0.4500, 0.1600],\n",
            "        [0.6700, 0.3100, 0.4700, 0.1500],\n",
            "        [0.6300, 0.2300, 0.4400, 0.1300],\n",
            "        [0.5600, 0.3000, 0.4100, 0.1300],\n",
            "        [0.5500, 0.2500, 0.4000, 0.1300],\n",
            "        [0.5500, 0.2600, 0.4400, 0.1200],\n",
            "        [0.6100, 0.3000, 0.4600, 0.1400],\n",
            "        [0.5800, 0.2600, 0.4000, 0.1200],\n",
            "        [0.5000, 0.2300, 0.3300, 0.1000],\n",
            "        [0.5600, 0.2700, 0.4200, 0.1300],\n",
            "        [0.5700, 0.3000, 0.4200, 0.1200],\n",
            "        [0.5700, 0.2900, 0.4200, 0.1300],\n",
            "        [0.6200, 0.2900, 0.4300, 0.1300],\n",
            "        [0.5100, 0.2500, 0.3000, 0.1100],\n",
            "        [0.5700, 0.2800, 0.4100, 0.1300],\n",
            "        [0.6300, 0.3300, 0.6000, 0.2500],\n",
            "        [0.5800, 0.2700, 0.5100, 0.1900],\n",
            "        [0.7100, 0.3000, 0.5900, 0.2100],\n",
            "        [0.6300, 0.2900, 0.5600, 0.1800],\n",
            "        [0.6500, 0.3000, 0.5800, 0.2200],\n",
            "        [0.7600, 0.3000, 0.6600, 0.2100],\n",
            "        [0.4900, 0.2500, 0.4500, 0.1700],\n",
            "        [0.7300, 0.2900, 0.6300, 0.1800],\n",
            "        [0.6700, 0.2500, 0.5800, 0.1800],\n",
            "        [0.7200, 0.3600, 0.6100, 0.2500],\n",
            "        [0.6500, 0.3200, 0.5100, 0.2000],\n",
            "        [0.6400, 0.2700, 0.5300, 0.1900],\n",
            "        [0.6800, 0.3000, 0.5500, 0.2100],\n",
            "        [0.5700, 0.2500, 0.5000, 0.2000],\n",
            "        [0.5800, 0.2800, 0.5100, 0.2400],\n",
            "        [0.6400, 0.3200, 0.5300, 0.2300],\n",
            "        [0.6500, 0.3000, 0.5500, 0.1800],\n",
            "        [0.7700, 0.3800, 0.6700, 0.2200],\n",
            "        [0.7700, 0.2600, 0.6900, 0.2300],\n",
            "        [0.6000, 0.2200, 0.5000, 0.1500],\n",
            "        [0.6900, 0.3200, 0.5700, 0.2300],\n",
            "        [0.5600, 0.2800, 0.4900, 0.2000],\n",
            "        [0.7700, 0.2800, 0.6700, 0.2000],\n",
            "        [0.6300, 0.2700, 0.4900, 0.1800],\n",
            "        [0.6700, 0.3300, 0.5700, 0.2100],\n",
            "        [0.7200, 0.3200, 0.6000, 0.1800],\n",
            "        [0.6200, 0.2800, 0.4800, 0.1800],\n",
            "        [0.6100, 0.3000, 0.4900, 0.1800],\n",
            "        [0.6400, 0.2800, 0.5600, 0.2100],\n",
            "        [0.7200, 0.3000, 0.5800, 0.1600],\n",
            "        [0.7400, 0.2800, 0.6100, 0.1900],\n",
            "        [0.7900, 0.3800, 0.6400, 0.2000],\n",
            "        [0.6400, 0.2800, 0.5600, 0.2200],\n",
            "        [0.6300, 0.2800, 0.5100, 0.1500],\n",
            "        [0.6100, 0.2600, 0.5600, 0.1400],\n",
            "        [0.7700, 0.3000, 0.6100, 0.2300],\n",
            "        [0.6300, 0.3400, 0.5600, 0.2400],\n",
            "        [0.6400, 0.3100, 0.5500, 0.1800],\n",
            "        [0.6000, 0.3000, 0.4800, 0.1800],\n",
            "        [0.6900, 0.3100, 0.5400, 0.2100],\n",
            "        [0.6700, 0.3100, 0.5600, 0.2400],\n",
            "        [0.6900, 0.3100, 0.5100, 0.2300],\n",
            "        [0.5800, 0.2700, 0.5100, 0.1900],\n",
            "        [0.6800, 0.3200, 0.5900, 0.2300],\n",
            "        [0.6700, 0.3300, 0.5700, 0.2500],\n",
            "        [0.6700, 0.3000, 0.5200, 0.2300],\n",
            "        [0.6300, 0.2500, 0.5000, 0.1900],\n",
            "        [0.6500, 0.3000, 0.5200, 0.2000],\n",
            "        [0.6200, 0.3400, 0.5400, 0.2300],\n",
            "        [0.5900, 0.3000, 0.5100, 0.1800]]) tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1.])\n",
            "tensor([[0.5100, 0.3700, 0.1500, 0.0400],\n",
            "        [0.4800, 0.3100, 0.1600, 0.0200],\n",
            "        [0.6000, 0.2700, 0.5100, 0.1600],\n",
            "        [0.5900, 0.3000, 0.5100, 0.1800],\n",
            "        [0.5000, 0.2300, 0.3300, 0.1000],\n",
            "        [0.5400, 0.3000, 0.4500, 0.1500],\n",
            "        [0.6900, 0.3100, 0.4900, 0.1500],\n",
            "        [0.6700, 0.3300, 0.5700, 0.2500],\n",
            "        [0.4900, 0.2400, 0.3300, 0.1000],\n",
            "        [0.5200, 0.3500, 0.1500, 0.0200],\n",
            "        [0.6000, 0.3000, 0.4800, 0.1800],\n",
            "        [0.7300, 0.2900, 0.6300, 0.1800],\n",
            "        [0.5800, 0.2700, 0.5100, 0.1900],\n",
            "        [0.5000, 0.3500, 0.1600, 0.0600],\n",
            "        [0.5600, 0.3000, 0.4500, 0.1500],\n",
            "        [0.5800, 0.2700, 0.5100, 0.1900],\n",
            "        [0.4600, 0.3100, 0.1500, 0.0200],\n",
            "        [0.5700, 0.3800, 0.1700, 0.0300],\n",
            "        [0.5400, 0.3900, 0.1300, 0.0400],\n",
            "        [0.7700, 0.2800, 0.6700, 0.2000],\n",
            "        [0.4600, 0.3400, 0.1400, 0.0300],\n",
            "        [0.7200, 0.3600, 0.6100, 0.2500],\n",
            "        [0.5400, 0.3400, 0.1500, 0.0400],\n",
            "        [0.6700, 0.2500, 0.5800, 0.1800],\n",
            "        [0.6500, 0.3200, 0.5100, 0.2000],\n",
            "        [0.5600, 0.3000, 0.4100, 0.1300],\n",
            "        [0.6200, 0.3400, 0.5400, 0.2300],\n",
            "        [0.4400, 0.3000, 0.1300, 0.0200],\n",
            "        [0.6700, 0.3100, 0.4700, 0.1500],\n",
            "        [0.5700, 0.2600, 0.3500, 0.1000],\n",
            "        [0.6000, 0.2200, 0.5000, 0.1500],\n",
            "        [0.6900, 0.3100, 0.5100, 0.2300],\n",
            "        [0.5000, 0.2000, 0.3500, 0.1000],\n",
            "        [0.4800, 0.3000, 0.1400, 0.0300],\n",
            "        [0.7600, 0.3000, 0.6600, 0.2100],\n",
            "        [0.6300, 0.2900, 0.5600, 0.1800],\n",
            "        [0.6900, 0.3200, 0.5700, 0.2300],\n",
            "        [0.5200, 0.3400, 0.1400, 0.0200],\n",
            "        [0.6100, 0.2800, 0.4700, 0.1200],\n",
            "        [0.6700, 0.3300, 0.5700, 0.2100],\n",
            "        [0.5500, 0.4200, 0.1400, 0.0200],\n",
            "        [0.6500, 0.3000, 0.5200, 0.2000],\n",
            "        [0.5700, 0.4400, 0.1500, 0.0400],\n",
            "        [0.5500, 0.3500, 0.1300, 0.0200],\n",
            "        [0.7200, 0.3200, 0.6000, 0.1800],\n",
            "        [0.4400, 0.2900, 0.1400, 0.0200],\n",
            "        [0.6300, 0.3300, 0.4700, 0.1600],\n",
            "        [0.4600, 0.3600, 0.1000, 0.0200],\n",
            "        [0.6700, 0.3000, 0.5200, 0.2300],\n",
            "        [0.6800, 0.3200, 0.5900, 0.2300],\n",
            "        [0.5600, 0.2900, 0.3600, 0.1300],\n",
            "        [0.5400, 0.3900, 0.1700, 0.0400],\n",
            "        [0.6400, 0.3200, 0.4500, 0.1500],\n",
            "        [0.4800, 0.3400, 0.1900, 0.0200],\n",
            "        [0.5500, 0.2500, 0.4000, 0.1300],\n",
            "        [0.6500, 0.2800, 0.4600, 0.1500],\n",
            "        [0.5000, 0.3400, 0.1600, 0.0400],\n",
            "        [0.6100, 0.2600, 0.5600, 0.1400],\n",
            "        [0.5300, 0.3700, 0.1500, 0.0200],\n",
            "        [0.7200, 0.3000, 0.5800, 0.1600],\n",
            "        [0.6700, 0.3000, 0.5000, 0.1700],\n",
            "        [0.6500, 0.3000, 0.5800, 0.2200],\n",
            "        [0.6900, 0.3100, 0.5400, 0.2100],\n",
            "        [0.4300, 0.3000, 0.1100, 0.0100],\n",
            "        [0.5900, 0.3000, 0.4200, 0.1500],\n",
            "        [0.5100, 0.3300, 0.1700, 0.0500],\n",
            "        [0.4700, 0.3200, 0.1600, 0.0200],\n",
            "        [0.6600, 0.3000, 0.4400, 0.1400],\n",
            "        [0.4900, 0.3100, 0.1500, 0.0200],\n",
            "        [0.5000, 0.3300, 0.1400, 0.0200],\n",
            "        [0.6100, 0.2800, 0.4000, 0.1300],\n",
            "        [0.5600, 0.2800, 0.4900, 0.2000],\n",
            "        [0.6100, 0.3000, 0.4600, 0.1400],\n",
            "        [0.5500, 0.2400, 0.3800, 0.1100],\n",
            "        [0.5700, 0.3000, 0.4200, 0.1200],\n",
            "        [0.5200, 0.2700, 0.3900, 0.1400],\n",
            "        [0.7900, 0.3800, 0.6400, 0.2000],\n",
            "        [0.6400, 0.2800, 0.5600, 0.2100],\n",
            "        [0.5000, 0.3000, 0.1600, 0.0200],\n",
            "        [0.4600, 0.3200, 0.1400, 0.0200],\n",
            "        [0.4900, 0.3100, 0.1500, 0.0100],\n",
            "        [0.6400, 0.2900, 0.4300, 0.1300],\n",
            "        [0.4800, 0.3400, 0.1600, 0.0200],\n",
            "        [0.5800, 0.2700, 0.3900, 0.1200],\n",
            "        [0.4700, 0.3200, 0.1300, 0.0200],\n",
            "        [0.4400, 0.3200, 0.1300, 0.0200],\n",
            "        [0.5900, 0.3200, 0.4800, 0.1800],\n",
            "        [0.5000, 0.3200, 0.1200, 0.0200],\n",
            "        [0.6300, 0.2500, 0.5000, 0.1900],\n",
            "        [0.5500, 0.2300, 0.4000, 0.1300],\n",
            "        [0.5100, 0.3800, 0.1500, 0.0300],\n",
            "        [0.5800, 0.2700, 0.4100, 0.1000],\n",
            "        [0.5600, 0.2500, 0.3900, 0.1100],\n",
            "        [0.5000, 0.3500, 0.1300, 0.0300],\n",
            "        [0.5700, 0.2800, 0.4500, 0.1300],\n",
            "        [0.6400, 0.2800, 0.5600, 0.2200],\n",
            "        [0.6800, 0.3000, 0.5500, 0.2100],\n",
            "        [0.5800, 0.4000, 0.1200, 0.0200],\n",
            "        [0.5500, 0.2600, 0.4400, 0.1200],\n",
            "        [0.5600, 0.2700, 0.4200, 0.1300],\n",
            "        [0.5400, 0.3700, 0.1500, 0.0200],\n",
            "        [0.6300, 0.3400, 0.5600, 0.2400],\n",
            "        [0.6200, 0.2900, 0.4300, 0.1300],\n",
            "        [0.5100, 0.3500, 0.1400, 0.0200],\n",
            "        [0.5000, 0.3400, 0.1500, 0.0200],\n",
            "        [0.7700, 0.2600, 0.6900, 0.2300],\n",
            "        [0.6800, 0.2800, 0.4800, 0.1400],\n",
            "        [0.6300, 0.2700, 0.4900, 0.1800],\n",
            "        [0.5500, 0.2400, 0.3700, 0.1000],\n",
            "        [0.6400, 0.3200, 0.5300, 0.2300],\n",
            "        [0.5100, 0.3800, 0.1600, 0.0200],\n",
            "        [0.6200, 0.2200, 0.4500, 0.1500],\n",
            "        [0.4900, 0.2500, 0.4500, 0.1700],\n",
            "        [0.4900, 0.3000, 0.1400, 0.0200],\n",
            "        [0.6100, 0.3000, 0.4900, 0.1800],\n",
            "        [0.5100, 0.2500, 0.3000, 0.1100],\n",
            "        [0.6500, 0.3000, 0.5500, 0.1800],\n",
            "        [0.6700, 0.3100, 0.4400, 0.1400],\n",
            "        [0.6000, 0.2200, 0.4000, 0.1000],\n",
            "        [0.5000, 0.3600, 0.1400, 0.0200],\n",
            "        [0.4900, 0.3600, 0.1400, 0.0100],\n",
            "        [0.5100, 0.3400, 0.1500, 0.0200],\n",
            "        [0.7000, 0.3200, 0.4700, 0.1400],\n",
            "        [0.5700, 0.2800, 0.4100, 0.1300],\n",
            "        [0.6600, 0.2900, 0.4600, 0.1300],\n",
            "        [0.5700, 0.2900, 0.4200, 0.1300],\n",
            "        [0.7700, 0.3800, 0.6700, 0.2200],\n",
            "        [0.5400, 0.3400, 0.1700, 0.0200],\n",
            "        [0.4500, 0.2300, 0.1300, 0.0300],\n",
            "        [0.6300, 0.3300, 0.6000, 0.2500],\n",
            "        [0.7100, 0.3000, 0.5900, 0.2100],\n",
            "        [0.5800, 0.2600, 0.4000, 0.1200],\n",
            "        [0.6000, 0.2900, 0.4500, 0.1500],\n",
            "        [0.7700, 0.3000, 0.6100, 0.2300],\n",
            "        [0.5100, 0.3800, 0.1900, 0.0400],\n",
            "        [0.6000, 0.3400, 0.4500, 0.1600],\n",
            "        [0.6300, 0.2500, 0.4900, 0.1500],\n",
            "        [0.6200, 0.2800, 0.4800, 0.1800],\n",
            "        [0.5700, 0.2500, 0.5000, 0.2000],\n",
            "        [0.6400, 0.3100, 0.5500, 0.1800],\n",
            "        [0.4800, 0.3000, 0.1400, 0.0100],\n",
            "        [0.6700, 0.3100, 0.5600, 0.2400],\n",
            "        [0.5100, 0.3500, 0.1400, 0.0300],\n",
            "        [0.5200, 0.4100, 0.1500, 0.0100],\n",
            "        [0.6100, 0.2900, 0.4700, 0.1400],\n",
            "        [0.6300, 0.2300, 0.4400, 0.1300],\n",
            "        [0.6300, 0.2800, 0.5100, 0.1500],\n",
            "        [0.5800, 0.2800, 0.5100, 0.2400],\n",
            "        [0.6400, 0.2700, 0.5300, 0.1900],\n",
            "        [0.7400, 0.2800, 0.6100, 0.1900]]) tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
            "        0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1.,\n",
            "        1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
            "        0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
            "        0., 0., 1., 1., 1., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separar os dados em treinamento e testes\n",
        "entrada_treinamento = entrada[0:120, :]\n",
        "saida_treinamento = saida[0:120]\n",
        "entrada_testes = entrada[120:150, :]\n",
        "saida_testes = saida[120:150]\n",
        "print(entrada_testes)\n",
        "print(saida_testes)"
      ],
      "metadata": {
        "id": "XZaa73CpqOLg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb910275-6a75-43b5-9a7c-6a48a140ae08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4900, 0.3600, 0.1400, 0.0100],\n",
            "        [0.5100, 0.3400, 0.1500, 0.0200],\n",
            "        [0.7000, 0.3200, 0.4700, 0.1400],\n",
            "        [0.5700, 0.2800, 0.4100, 0.1300],\n",
            "        [0.6600, 0.2900, 0.4600, 0.1300],\n",
            "        [0.5700, 0.2900, 0.4200, 0.1300],\n",
            "        [0.7700, 0.3800, 0.6700, 0.2200],\n",
            "        [0.5400, 0.3400, 0.1700, 0.0200],\n",
            "        [0.4500, 0.2300, 0.1300, 0.0300],\n",
            "        [0.6300, 0.3300, 0.6000, 0.2500],\n",
            "        [0.7100, 0.3000, 0.5900, 0.2100],\n",
            "        [0.5800, 0.2600, 0.4000, 0.1200],\n",
            "        [0.6000, 0.2900, 0.4500, 0.1500],\n",
            "        [0.7700, 0.3000, 0.6100, 0.2300],\n",
            "        [0.5100, 0.3800, 0.1900, 0.0400],\n",
            "        [0.6000, 0.3400, 0.4500, 0.1600],\n",
            "        [0.6300, 0.2500, 0.4900, 0.1500],\n",
            "        [0.6200, 0.2800, 0.4800, 0.1800],\n",
            "        [0.5700, 0.2500, 0.5000, 0.2000],\n",
            "        [0.6400, 0.3100, 0.5500, 0.1800],\n",
            "        [0.4800, 0.3000, 0.1400, 0.0100],\n",
            "        [0.6700, 0.3100, 0.5600, 0.2400],\n",
            "        [0.5100, 0.3500, 0.1400, 0.0300],\n",
            "        [0.5200, 0.4100, 0.1500, 0.0100],\n",
            "        [0.6100, 0.2900, 0.4700, 0.1400],\n",
            "        [0.6300, 0.2300, 0.4400, 0.1300],\n",
            "        [0.6300, 0.2800, 0.5100, 0.1500],\n",
            "        [0.5800, 0.2800, 0.5100, 0.2400],\n",
            "        [0.6400, 0.2700, 0.5300, 0.1900],\n",
            "        [0.7400, 0.2800, 0.6100, 0.1900]])\n",
            "tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
            "        1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Montar o modelo para o treinamento\n",
        "print(entrada_treinamento.size())\n",
        "input_size = entrada_treinamento.size()[1]\n",
        "hidden_size = 10\n",
        "modelo = Net(input_size, hidden_size)\n",
        "print(modelo)\n",
        "\n",
        "# Configurações do modelo\n",
        "criterion = torch.nn.BCELoss() # Binary Cross Entropy\n",
        "criterion = torch.nn.MSELoss() # Mean Square Error\n",
        "optimizer = torch.optim.SGD(modelo.parameters(), lr = 0.9, momentum = 0.3)"
      ],
      "metadata": {
        "id": "K4uV264Mqg1A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a34cf34-bfc9-4aa5-a075-922dd25af45a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([120, 4])\n",
            "Net(\n",
            "  (fc1): Linear(in_features=4, out_features=10, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (fc2): Linear(in_features=10, out_features=1, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Treinar o modelo\n",
        "\n",
        "epochs = 10001 # Quantidade de épocas de treinamento\n",
        "\n",
        "errors = [] # Criando um array vazio para guardar os erros de cada epoca\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  optimizer.zero_grad()\n",
        "  # Forward pass\n",
        "  y_pred = modelo(entrada_treinamento)\n",
        "  #Compute Loss\n",
        "  loss = criterion(y_pred.squeeze(), saida_treinamento)\n",
        "  errors.append(loss.item())\n",
        "  if epoch % 100 == 0:\n",
        "    print('Epoch {}: train loss: {}'.format(epoch, loss.item()))\n",
        "  #Backward pass\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "id": "giFUNi_6qnFx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84e92b54-23a8-48f7-fb72-f111e63f1dba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: train loss: 0.2769414186477661\n",
            "Epoch 100: train loss: 0.10381046682596207\n",
            "Epoch 200: train loss: 0.0561031810939312\n",
            "Epoch 300: train loss: 0.0393059179186821\n",
            "Epoch 400: train loss: 0.0311997402459383\n",
            "Epoch 500: train loss: 0.026417536661028862\n",
            "Epoch 600: train loss: 0.023316780105233192\n",
            "Epoch 700: train loss: 0.02119060419499874\n",
            "Epoch 800: train loss: 0.01966588757932186\n",
            "Epoch 900: train loss: 0.018529387190937996\n",
            "Epoch 1000: train loss: 0.017658106982707977\n",
            "Epoch 1100: train loss: 0.016969718039035797\n",
            "Epoch 1200: train loss: 0.016412127763032913\n",
            "Epoch 1300: train loss: 0.015950847417116165\n",
            "Epoch 1400: train loss: 0.015562174841761589\n",
            "Epoch 1500: train loss: 0.015229412354528904\n",
            "Epoch 1600: train loss: 0.014941154047846794\n",
            "Epoch 1700: train loss: 0.014688109047710896\n",
            "Epoch 1800: train loss: 0.014463230036199093\n",
            "Epoch 1900: train loss: 0.014261486940085888\n",
            "Epoch 2000: train loss: 0.014078961685299873\n",
            "Epoch 2100: train loss: 0.01391326729208231\n",
            "Epoch 2200: train loss: 0.013761392794549465\n",
            "Epoch 2300: train loss: 0.013621101155877113\n",
            "Epoch 2400: train loss: 0.013491008430719376\n",
            "Epoch 2500: train loss: 0.013369696214795113\n",
            "Epoch 2600: train loss: 0.013255849480628967\n",
            "Epoch 2700: train loss: 0.01314858440309763\n",
            "Epoch 2800: train loss: 0.01304713822901249\n",
            "Epoch 2900: train loss: 0.012951179407536983\n",
            "Epoch 3000: train loss: 0.012859891168773174\n",
            "Epoch 3100: train loss: 0.012772675603628159\n",
            "Epoch 3200: train loss: 0.012689121998846531\n",
            "Epoch 3300: train loss: 0.012608865275979042\n",
            "Epoch 3400: train loss: 0.01253160834312439\n",
            "Epoch 3500: train loss: 0.012457060627639294\n",
            "Epoch 3600: train loss: 0.012385002337396145\n",
            "Epoch 3700: train loss: 0.012315195985138416\n",
            "Epoch 3800: train loss: 0.01224745437502861\n",
            "Epoch 3900: train loss: 0.012181616388261318\n",
            "Epoch 4000: train loss: 0.012117529287934303\n",
            "Epoch 4100: train loss: 0.01205506268888712\n",
            "Epoch 4200: train loss: 0.011994078755378723\n",
            "Epoch 4300: train loss: 0.011934476904571056\n",
            "Epoch 4400: train loss: 0.011876157484948635\n",
            "Epoch 4500: train loss: 0.011819028295576572\n",
            "Epoch 4600: train loss: 0.01176301296800375\n",
            "Epoch 4700: train loss: 0.011708054691553116\n",
            "Epoch 4800: train loss: 0.011654146946966648\n",
            "Epoch 4900: train loss: 0.011601269245147705\n",
            "Epoch 5000: train loss: 0.01154935359954834\n",
            "Epoch 5100: train loss: 0.011498249135911465\n",
            "Epoch 5200: train loss: 0.011447909288108349\n",
            "Epoch 5300: train loss: 0.011398321017622948\n",
            "Epoch 5400: train loss: 0.01134943962097168\n",
            "Epoch 5500: train loss: 0.011301211081445217\n",
            "Epoch 5600: train loss: 0.011253594420850277\n",
            "Epoch 5700: train loss: 0.01120657380670309\n",
            "Epoch 5800: train loss: 0.011160185560584068\n",
            "Epoch 5900: train loss: 0.011114346794784069\n",
            "Epoch 6000: train loss: 0.0110690388828516\n",
            "Epoch 6100: train loss: 0.01102424319833517\n",
            "Epoch 6200: train loss: 0.010979951359331608\n",
            "Epoch 6300: train loss: 0.010936141945421696\n",
            "Epoch 6400: train loss: 0.010892814956605434\n",
            "Epoch 6500: train loss: 0.010849952697753906\n",
            "Epoch 6600: train loss: 0.010807554237544537\n",
            "Epoch 6700: train loss: 0.01076560653746128\n",
            "Epoch 6800: train loss: 0.010724097490310669\n",
            "Epoch 6900: train loss: 0.010683038271963596\n",
            "Epoch 7000: train loss: 0.010642406530678272\n",
            "Epoch 7100: train loss: 0.010602238588035107\n",
            "Epoch 7200: train loss: 0.01056259498000145\n",
            "Epoch 7300: train loss: 0.010523354634642601\n",
            "Epoch 7400: train loss: 0.010484537109732628\n",
            "Epoch 7500: train loss: 0.010446133092045784\n",
            "Epoch 7600: train loss: 0.010408121161162853\n",
            "Epoch 7700: train loss: 0.010370517149567604\n",
            "Epoch 7800: train loss: 0.010333303362131119\n",
            "Epoch 7900: train loss: 0.010296480730175972\n",
            "Epoch 8000: train loss: 0.01026004459708929\n",
            "Epoch 8100: train loss: 0.010223993100225925\n",
            "Epoch 8200: train loss: 0.010188322514295578\n",
            "Epoch 8300: train loss: 0.01015302911400795\n",
            "Epoch 8400: train loss: 0.010118125937879086\n",
            "Epoch 8500: train loss: 0.010083612985908985\n",
            "Epoch 8600: train loss: 0.010049471631646156\n",
            "Epoch 8700: train loss: 0.010015701875090599\n",
            "Epoch 8800: train loss: 0.009982315823435783\n",
            "Epoch 8900: train loss: 0.009949342347681522\n",
            "Epoch 9000: train loss: 0.009916718117892742\n",
            "Epoch 9100: train loss: 0.009884437546133995\n",
            "Epoch 9200: train loss: 0.009852485731244087\n",
            "Epoch 9300: train loss: 0.009820898063480854\n",
            "Epoch 9400: train loss: 0.009789626114070415\n",
            "Epoch 9500: train loss: 0.009758695028722286\n",
            "Epoch 9600: train loss: 0.009728079661726952\n",
            "Epoch 9700: train loss: 0.00969779770821333\n",
            "Epoch 9800: train loss: 0.009667827747762203\n",
            "Epoch 9900: train loss: 0.009638176299631596\n",
            "Epoch 10000: train loss: 0.009608844295144081\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teste = np.array([5.2,2.1,3.6,1.6])\n",
        "testetensor = torch.FloatTensor(teste)\n",
        "testetensor /= 10\n",
        "y_pred = modelo(testetensor)"
      ],
      "metadata": {
        "id": "AvWQDDLglbYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rodar a rede com os dados de teste, os dados que a rede nunca viu\n",
        "#y_pred = modelo(entrada_testes)\n",
        "#print(y_pred) # valor previsto pela rede\n",
        "#print(saida_testes) # valor real"
      ],
      "metadata": {
        "id": "XNzsxwu1quIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "def plotcharts(errors):\n",
        "    errors = np.array(errors)\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    graf02 = plt.subplot(1, 2, 1) # nrows, ncols, index\n",
        "    graf02.set_title('Errors')\n",
        "    plt.plot(errors, '-')\n",
        "    plt.xlabel('Epochs')\n",
        "    graf03 = plt.subplot(1, 2, 2)\n",
        "    graf03.set_title('Tests')\n",
        "    a = plt.plot(saida_testes.numpy(), 'yo', label='Real')\n",
        "    plt.setp(a, markersize=10)\n",
        "    a = plt.plot(y_pred.detach().numpy(), 'b+', label='Predicted')\n",
        "    plt.setp(a, markersize=10)\n",
        "    plt.legend(loc=7)\n",
        "    plt.show()\n",
        "plotcharts(errors)"
      ],
      "metadata": {
        "id": "2y00-_Zwqz-g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "5a3d6e31-e4e4-4712-e9b6-be8c935f5976"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes.size"
      ],
      "metadata": {
        "id": "UtBrwxWyoBgs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ec433e3-48d2-4c3a-bc96-1e23dc02574a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}