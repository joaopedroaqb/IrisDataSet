{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "619Fcv2Zoe3h"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "novoArray = np.random.rand(5,5)\n",
        "print(novoArray)\n",
        "print(type(novoArray))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHQKnJfVoqb8",
        "outputId": "6b464a16-f7d7-461d-84d1-dc03687f6af9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.86961509 0.84008225 0.52798764 0.36721821 0.75706453]\n",
            " [0.18957512 0.69970046 0.50452021 0.59865332 0.79380532]\n",
            " [0.38582129 0.90233491 0.12905016 0.51519777 0.01788103]\n",
            " [0.9704663  0.88959166 0.96510515 0.77941092 0.52586997]\n",
            " [0.10756517 0.81489968 0.1291654  0.67668407 0.23127215]]\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tensor vs Array\n",
        "novoTensor = torch.rand(5,5)\n",
        "print(novoTensor) \n",
        "print(type(novoTensor)) \n",
        "print(novoArray)\n",
        "print(type(novoArray))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMfvca8joqeq",
        "outputId": "1c710e9b-e2ab-4b4d-8565-0b648b08e503"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6486, 0.7720, 0.6343, 0.1670, 0.3531],\n",
            "        [0.4211, 0.8863, 0.0625, 0.9482, 0.4165],\n",
            "        [0.2299, 0.1717, 0.9903, 0.6618, 0.3319],\n",
            "        [0.1296, 0.9636, 0.2834, 0.7338, 0.0064],\n",
            "        [0.1286, 0.4020, 0.3526, 0.5710, 0.2450]])\n",
            "<class 'torch.Tensor'>\n",
            "[[0.86961509 0.84008225 0.52798764 0.36721821 0.75706453]\n",
            " [0.18957512 0.69970046 0.50452021 0.59865332 0.79380532]\n",
            " [0.38582129 0.90233491 0.12905016 0.51519777 0.01788103]\n",
            " [0.9704663  0.88959166 0.96510515 0.77941092 0.52586997]\n",
            " [0.10756517 0.81489968 0.1291654  0.67668407 0.23127215]]\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar um modelo de Rede Neural\n",
        "class Net(torch.nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(Net, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size) #full connected\n",
        "    self.relu = torch.nn.ReLU() #(0, infinito)\n",
        "    self.fc2 = torch.nn.Linear(self.hidden_size, 1)\n",
        "    self.sigmoid = torch.nn.Sigmoid() #(0, 1)\n",
        "  def forward(self, x):\n",
        "    hidden = self.fc1(x)\n",
        "    relu = self.relu(hidden)\n",
        "    output = self.fc2(relu)\n",
        "    output = self.sigmoid(output)\n",
        "    return output"
      ],
      "metadata": {
        "id": "VOJvDjlPouuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()\n",
        "# data, target, target_names\n",
        "# print(iris)\n",
        "dados = iris.data\n",
        "classes = iris.target\n",
        "nomesClasses = iris.target_names"
      ],
      "metadata": {
        "id": "uT9VwYqrozrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converter as classes\n",
        "print(classes)\n",
        "print(nomesClasses)\n",
        "import numpy as np\n",
        "# saida = np.where(condição, true, false)\n",
        "# saida = np.where(classes==2, 1, 0) # virginica\n",
        "saida = np.where(classes== 2, 0, classes)\n",
        "print(saida)\n",
        "# 0: setosa; 1: versicolor; 2: virginica;\n",
        "# 0: setosa; 0: versicolor; 1: virginica;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEAonZ4go0ac",
        "outputId": "65cdf02a-e5ac-49f5-8440-23c67d6875d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n",
            "['setosa' 'versicolor' 'virginica']\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Converter para tensor\n",
        "entrada = torch.FloatTensor(dados) / 10\n",
        "saida = torch.FloatTensor(saida)\n",
        "print(torch.max(entrada))\n",
        "print(saida)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-Uvv_piqJwZ",
        "outputId": "04621661-b830-46df-dbc0-87a130008e9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7900)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "print(entrada, saida)\n",
        "entrada, saida = shuffle(entrada, saida)\n",
        "print(entrada, saida)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojUIQTmkqKuQ",
        "outputId": "0e3076f3-24ab-4055-dbdb-a567caa10b9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5100, 0.3500, 0.1400, 0.0200],\n",
            "        [0.4900, 0.3000, 0.1400, 0.0200],\n",
            "        [0.4700, 0.3200, 0.1300, 0.0200],\n",
            "        [0.4600, 0.3100, 0.1500, 0.0200],\n",
            "        [0.5000, 0.3600, 0.1400, 0.0200],\n",
            "        [0.5400, 0.3900, 0.1700, 0.0400],\n",
            "        [0.4600, 0.3400, 0.1400, 0.0300],\n",
            "        [0.5000, 0.3400, 0.1500, 0.0200],\n",
            "        [0.4400, 0.2900, 0.1400, 0.0200],\n",
            "        [0.4900, 0.3100, 0.1500, 0.0100],\n",
            "        [0.5400, 0.3700, 0.1500, 0.0200],\n",
            "        [0.4800, 0.3400, 0.1600, 0.0200],\n",
            "        [0.4800, 0.3000, 0.1400, 0.0100],\n",
            "        [0.4300, 0.3000, 0.1100, 0.0100],\n",
            "        [0.5800, 0.4000, 0.1200, 0.0200],\n",
            "        [0.5700, 0.4400, 0.1500, 0.0400],\n",
            "        [0.5400, 0.3900, 0.1300, 0.0400],\n",
            "        [0.5100, 0.3500, 0.1400, 0.0300],\n",
            "        [0.5700, 0.3800, 0.1700, 0.0300],\n",
            "        [0.5100, 0.3800, 0.1500, 0.0300],\n",
            "        [0.5400, 0.3400, 0.1700, 0.0200],\n",
            "        [0.5100, 0.3700, 0.1500, 0.0400],\n",
            "        [0.4600, 0.3600, 0.1000, 0.0200],\n",
            "        [0.5100, 0.3300, 0.1700, 0.0500],\n",
            "        [0.4800, 0.3400, 0.1900, 0.0200],\n",
            "        [0.5000, 0.3000, 0.1600, 0.0200],\n",
            "        [0.5000, 0.3400, 0.1600, 0.0400],\n",
            "        [0.5200, 0.3500, 0.1500, 0.0200],\n",
            "        [0.5200, 0.3400, 0.1400, 0.0200],\n",
            "        [0.4700, 0.3200, 0.1600, 0.0200],\n",
            "        [0.4800, 0.3100, 0.1600, 0.0200],\n",
            "        [0.5400, 0.3400, 0.1500, 0.0400],\n",
            "        [0.5200, 0.4100, 0.1500, 0.0100],\n",
            "        [0.5500, 0.4200, 0.1400, 0.0200],\n",
            "        [0.4900, 0.3100, 0.1500, 0.0200],\n",
            "        [0.5000, 0.3200, 0.1200, 0.0200],\n",
            "        [0.5500, 0.3500, 0.1300, 0.0200],\n",
            "        [0.4900, 0.3600, 0.1400, 0.0100],\n",
            "        [0.4400, 0.3000, 0.1300, 0.0200],\n",
            "        [0.5100, 0.3400, 0.1500, 0.0200],\n",
            "        [0.5000, 0.3500, 0.1300, 0.0300],\n",
            "        [0.4500, 0.2300, 0.1300, 0.0300],\n",
            "        [0.4400, 0.3200, 0.1300, 0.0200],\n",
            "        [0.5000, 0.3500, 0.1600, 0.0600],\n",
            "        [0.5100, 0.3800, 0.1900, 0.0400],\n",
            "        [0.4800, 0.3000, 0.1400, 0.0300],\n",
            "        [0.5100, 0.3800, 0.1600, 0.0200],\n",
            "        [0.4600, 0.3200, 0.1400, 0.0200],\n",
            "        [0.5300, 0.3700, 0.1500, 0.0200],\n",
            "        [0.5000, 0.3300, 0.1400, 0.0200],\n",
            "        [0.7000, 0.3200, 0.4700, 0.1400],\n",
            "        [0.6400, 0.3200, 0.4500, 0.1500],\n",
            "        [0.6900, 0.3100, 0.4900, 0.1500],\n",
            "        [0.5500, 0.2300, 0.4000, 0.1300],\n",
            "        [0.6500, 0.2800, 0.4600, 0.1500],\n",
            "        [0.5700, 0.2800, 0.4500, 0.1300],\n",
            "        [0.6300, 0.3300, 0.4700, 0.1600],\n",
            "        [0.4900, 0.2400, 0.3300, 0.1000],\n",
            "        [0.6600, 0.2900, 0.4600, 0.1300],\n",
            "        [0.5200, 0.2700, 0.3900, 0.1400],\n",
            "        [0.5000, 0.2000, 0.3500, 0.1000],\n",
            "        [0.5900, 0.3000, 0.4200, 0.1500],\n",
            "        [0.6000, 0.2200, 0.4000, 0.1000],\n",
            "        [0.6100, 0.2900, 0.4700, 0.1400],\n",
            "        [0.5600, 0.2900, 0.3600, 0.1300],\n",
            "        [0.6700, 0.3100, 0.4400, 0.1400],\n",
            "        [0.5600, 0.3000, 0.4500, 0.1500],\n",
            "        [0.5800, 0.2700, 0.4100, 0.1000],\n",
            "        [0.6200, 0.2200, 0.4500, 0.1500],\n",
            "        [0.5600, 0.2500, 0.3900, 0.1100],\n",
            "        [0.5900, 0.3200, 0.4800, 0.1800],\n",
            "        [0.6100, 0.2800, 0.4000, 0.1300],\n",
            "        [0.6300, 0.2500, 0.4900, 0.1500],\n",
            "        [0.6100, 0.2800, 0.4700, 0.1200],\n",
            "        [0.6400, 0.2900, 0.4300, 0.1300],\n",
            "        [0.6600, 0.3000, 0.4400, 0.1400],\n",
            "        [0.6800, 0.2800, 0.4800, 0.1400],\n",
            "        [0.6700, 0.3000, 0.5000, 0.1700],\n",
            "        [0.6000, 0.2900, 0.4500, 0.1500],\n",
            "        [0.5700, 0.2600, 0.3500, 0.1000],\n",
            "        [0.5500, 0.2400, 0.3800, 0.1100],\n",
            "        [0.5500, 0.2400, 0.3700, 0.1000],\n",
            "        [0.5800, 0.2700, 0.3900, 0.1200],\n",
            "        [0.6000, 0.2700, 0.5100, 0.1600],\n",
            "        [0.5400, 0.3000, 0.4500, 0.1500],\n",
            "        [0.6000, 0.3400, 0.4500, 0.1600],\n",
            "        [0.6700, 0.3100, 0.4700, 0.1500],\n",
            "        [0.6300, 0.2300, 0.4400, 0.1300],\n",
            "        [0.5600, 0.3000, 0.4100, 0.1300],\n",
            "        [0.5500, 0.2500, 0.4000, 0.1300],\n",
            "        [0.5500, 0.2600, 0.4400, 0.1200],\n",
            "        [0.6100, 0.3000, 0.4600, 0.1400],\n",
            "        [0.5800, 0.2600, 0.4000, 0.1200],\n",
            "        [0.5000, 0.2300, 0.3300, 0.1000],\n",
            "        [0.5600, 0.2700, 0.4200, 0.1300],\n",
            "        [0.5700, 0.3000, 0.4200, 0.1200],\n",
            "        [0.5700, 0.2900, 0.4200, 0.1300],\n",
            "        [0.6200, 0.2900, 0.4300, 0.1300],\n",
            "        [0.5100, 0.2500, 0.3000, 0.1100],\n",
            "        [0.5700, 0.2800, 0.4100, 0.1300],\n",
            "        [0.6300, 0.3300, 0.6000, 0.2500],\n",
            "        [0.5800, 0.2700, 0.5100, 0.1900],\n",
            "        [0.7100, 0.3000, 0.5900, 0.2100],\n",
            "        [0.6300, 0.2900, 0.5600, 0.1800],\n",
            "        [0.6500, 0.3000, 0.5800, 0.2200],\n",
            "        [0.7600, 0.3000, 0.6600, 0.2100],\n",
            "        [0.4900, 0.2500, 0.4500, 0.1700],\n",
            "        [0.7300, 0.2900, 0.6300, 0.1800],\n",
            "        [0.6700, 0.2500, 0.5800, 0.1800],\n",
            "        [0.7200, 0.3600, 0.6100, 0.2500],\n",
            "        [0.6500, 0.3200, 0.5100, 0.2000],\n",
            "        [0.6400, 0.2700, 0.5300, 0.1900],\n",
            "        [0.6800, 0.3000, 0.5500, 0.2100],\n",
            "        [0.5700, 0.2500, 0.5000, 0.2000],\n",
            "        [0.5800, 0.2800, 0.5100, 0.2400],\n",
            "        [0.6400, 0.3200, 0.5300, 0.2300],\n",
            "        [0.6500, 0.3000, 0.5500, 0.1800],\n",
            "        [0.7700, 0.3800, 0.6700, 0.2200],\n",
            "        [0.7700, 0.2600, 0.6900, 0.2300],\n",
            "        [0.6000, 0.2200, 0.5000, 0.1500],\n",
            "        [0.6900, 0.3200, 0.5700, 0.2300],\n",
            "        [0.5600, 0.2800, 0.4900, 0.2000],\n",
            "        [0.7700, 0.2800, 0.6700, 0.2000],\n",
            "        [0.6300, 0.2700, 0.4900, 0.1800],\n",
            "        [0.6700, 0.3300, 0.5700, 0.2100],\n",
            "        [0.7200, 0.3200, 0.6000, 0.1800],\n",
            "        [0.6200, 0.2800, 0.4800, 0.1800],\n",
            "        [0.6100, 0.3000, 0.4900, 0.1800],\n",
            "        [0.6400, 0.2800, 0.5600, 0.2100],\n",
            "        [0.7200, 0.3000, 0.5800, 0.1600],\n",
            "        [0.7400, 0.2800, 0.6100, 0.1900],\n",
            "        [0.7900, 0.3800, 0.6400, 0.2000],\n",
            "        [0.6400, 0.2800, 0.5600, 0.2200],\n",
            "        [0.6300, 0.2800, 0.5100, 0.1500],\n",
            "        [0.6100, 0.2600, 0.5600, 0.1400],\n",
            "        [0.7700, 0.3000, 0.6100, 0.2300],\n",
            "        [0.6300, 0.3400, 0.5600, 0.2400],\n",
            "        [0.6400, 0.3100, 0.5500, 0.1800],\n",
            "        [0.6000, 0.3000, 0.4800, 0.1800],\n",
            "        [0.6900, 0.3100, 0.5400, 0.2100],\n",
            "        [0.6700, 0.3100, 0.5600, 0.2400],\n",
            "        [0.6900, 0.3100, 0.5100, 0.2300],\n",
            "        [0.5800, 0.2700, 0.5100, 0.1900],\n",
            "        [0.6800, 0.3200, 0.5900, 0.2300],\n",
            "        [0.6700, 0.3300, 0.5700, 0.2500],\n",
            "        [0.6700, 0.3000, 0.5200, 0.2300],\n",
            "        [0.6300, 0.2500, 0.5000, 0.1900],\n",
            "        [0.6500, 0.3000, 0.5200, 0.2000],\n",
            "        [0.6200, 0.3400, 0.5400, 0.2300],\n",
            "        [0.5900, 0.3000, 0.5100, 0.1800]]) tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0.])\n",
            "tensor([[0.5500, 0.2400, 0.3700, 0.1000],\n",
            "        [0.6000, 0.2200, 0.5000, 0.1500],\n",
            "        [0.5100, 0.2500, 0.3000, 0.1100],\n",
            "        [0.6300, 0.2500, 0.5000, 0.1900],\n",
            "        [0.4900, 0.3600, 0.1400, 0.0100],\n",
            "        [0.6300, 0.2300, 0.4400, 0.1300],\n",
            "        [0.6300, 0.3300, 0.4700, 0.1600],\n",
            "        [0.4600, 0.3400, 0.1400, 0.0300],\n",
            "        [0.6500, 0.3200, 0.5100, 0.2000],\n",
            "        [0.4700, 0.3200, 0.1600, 0.0200],\n",
            "        [0.6200, 0.3400, 0.5400, 0.2300],\n",
            "        [0.5700, 0.4400, 0.1500, 0.0400],\n",
            "        [0.6400, 0.3100, 0.5500, 0.1800],\n",
            "        [0.6000, 0.2700, 0.5100, 0.1600],\n",
            "        [0.5100, 0.3300, 0.1700, 0.0500],\n",
            "        [0.6100, 0.3000, 0.4900, 0.1800],\n",
            "        [0.6300, 0.2500, 0.4900, 0.1500],\n",
            "        [0.4800, 0.3000, 0.1400, 0.0300],\n",
            "        [0.6200, 0.2900, 0.4300, 0.1300],\n",
            "        [0.7400, 0.2800, 0.6100, 0.1900],\n",
            "        [0.5700, 0.2900, 0.4200, 0.1300],\n",
            "        [0.5200, 0.2700, 0.3900, 0.1400],\n",
            "        [0.4600, 0.3200, 0.1400, 0.0200],\n",
            "        [0.4900, 0.2500, 0.4500, 0.1700],\n",
            "        [0.4900, 0.3100, 0.1500, 0.0200],\n",
            "        [0.6500, 0.2800, 0.4600, 0.1500],\n",
            "        [0.7100, 0.3000, 0.5900, 0.2100],\n",
            "        [0.4800, 0.3400, 0.1600, 0.0200],\n",
            "        [0.6900, 0.3100, 0.5400, 0.2100],\n",
            "        [0.6700, 0.3000, 0.5200, 0.2300],\n",
            "        [0.7000, 0.3200, 0.4700, 0.1400],\n",
            "        [0.5600, 0.2800, 0.4900, 0.2000],\n",
            "        [0.5000, 0.2000, 0.3500, 0.1000],\n",
            "        [0.6800, 0.3200, 0.5900, 0.2300],\n",
            "        [0.7200, 0.3000, 0.5800, 0.1600],\n",
            "        [0.6300, 0.2800, 0.5100, 0.1500],\n",
            "        [0.5500, 0.2500, 0.4000, 0.1300],\n",
            "        [0.5100, 0.3800, 0.1900, 0.0400],\n",
            "        [0.4600, 0.3100, 0.1500, 0.0200],\n",
            "        [0.5400, 0.3900, 0.1700, 0.0400],\n",
            "        [0.5600, 0.2900, 0.3600, 0.1300],\n",
            "        [0.5400, 0.3900, 0.1300, 0.0400],\n",
            "        [0.6100, 0.2900, 0.4700, 0.1400],\n",
            "        [0.6100, 0.3000, 0.4600, 0.1400],\n",
            "        [0.5800, 0.2700, 0.5100, 0.1900],\n",
            "        [0.5800, 0.2700, 0.5100, 0.1900],\n",
            "        [0.7700, 0.3800, 0.6700, 0.2200],\n",
            "        [0.5800, 0.2700, 0.3900, 0.1200],\n",
            "        [0.6700, 0.3000, 0.5000, 0.1700],\n",
            "        [0.5000, 0.3300, 0.1400, 0.0200],\n",
            "        [0.6900, 0.3200, 0.5700, 0.2300],\n",
            "        [0.5800, 0.2600, 0.4000, 0.1200],\n",
            "        [0.6400, 0.3200, 0.4500, 0.1500],\n",
            "        [0.4300, 0.3000, 0.1100, 0.0100],\n",
            "        [0.7200, 0.3600, 0.6100, 0.2500],\n",
            "        [0.6300, 0.3300, 0.6000, 0.2500],\n",
            "        [0.5700, 0.2600, 0.3500, 0.1000],\n",
            "        [0.6700, 0.2500, 0.5800, 0.1800],\n",
            "        [0.6000, 0.2200, 0.4000, 0.1000],\n",
            "        [0.5100, 0.3700, 0.1500, 0.0400],\n",
            "        [0.4800, 0.3000, 0.1400, 0.0100],\n",
            "        [0.7200, 0.3200, 0.6000, 0.1800],\n",
            "        [0.5000, 0.3500, 0.1600, 0.0600],\n",
            "        [0.5700, 0.2800, 0.4500, 0.1300],\n",
            "        [0.4900, 0.2400, 0.3300, 0.1000],\n",
            "        [0.6900, 0.3100, 0.4900, 0.1500],\n",
            "        [0.6700, 0.3100, 0.4400, 0.1400],\n",
            "        [0.5600, 0.2500, 0.3900, 0.1100],\n",
            "        [0.4900, 0.3100, 0.1500, 0.0100],\n",
            "        [0.5200, 0.4100, 0.1500, 0.0100],\n",
            "        [0.7700, 0.3000, 0.6100, 0.2300],\n",
            "        [0.6600, 0.3000, 0.4400, 0.1400],\n",
            "        [0.7700, 0.2800, 0.6700, 0.2000],\n",
            "        [0.5500, 0.2600, 0.4400, 0.1200],\n",
            "        [0.6400, 0.2800, 0.5600, 0.2200],\n",
            "        [0.5000, 0.2300, 0.3300, 0.1000],\n",
            "        [0.6600, 0.2900, 0.4600, 0.1300],\n",
            "        [0.4800, 0.3100, 0.1600, 0.0200],\n",
            "        [0.6800, 0.2800, 0.4800, 0.1400],\n",
            "        [0.5700, 0.3000, 0.4200, 0.1200],\n",
            "        [0.4400, 0.2900, 0.1400, 0.0200],\n",
            "        [0.7700, 0.2600, 0.6900, 0.2300],\n",
            "        [0.6200, 0.2200, 0.4500, 0.1500],\n",
            "        [0.6100, 0.2600, 0.5600, 0.1400],\n",
            "        [0.6000, 0.3400, 0.4500, 0.1600],\n",
            "        [0.4400, 0.3200, 0.1300, 0.0200],\n",
            "        [0.5000, 0.3000, 0.1600, 0.0200],\n",
            "        [0.4800, 0.3400, 0.1900, 0.0200],\n",
            "        [0.5000, 0.3600, 0.1400, 0.0200],\n",
            "        [0.5000, 0.3500, 0.1300, 0.0300],\n",
            "        [0.5600, 0.3000, 0.4500, 0.1500],\n",
            "        [0.6500, 0.3000, 0.5500, 0.1800],\n",
            "        [0.5000, 0.3400, 0.1500, 0.0200],\n",
            "        [0.6400, 0.3200, 0.5300, 0.2300],\n",
            "        [0.5900, 0.3000, 0.4200, 0.1500],\n",
            "        [0.5100, 0.3800, 0.1500, 0.0300],\n",
            "        [0.5400, 0.3400, 0.1700, 0.0200],\n",
            "        [0.5400, 0.3400, 0.1500, 0.0400],\n",
            "        [0.5200, 0.3500, 0.1500, 0.0200],\n",
            "        [0.4400, 0.3000, 0.1300, 0.0200],\n",
            "        [0.6800, 0.3000, 0.5500, 0.2100],\n",
            "        [0.6300, 0.2900, 0.5600, 0.1800],\n",
            "        [0.5800, 0.4000, 0.1200, 0.0200],\n",
            "        [0.7300, 0.2900, 0.6300, 0.1800],\n",
            "        [0.6100, 0.2800, 0.4000, 0.1300],\n",
            "        [0.5100, 0.3500, 0.1400, 0.0200],\n",
            "        [0.6100, 0.2800, 0.4700, 0.1200],\n",
            "        [0.5900, 0.3000, 0.5100, 0.1800],\n",
            "        [0.6300, 0.2700, 0.4900, 0.1800],\n",
            "        [0.5100, 0.3400, 0.1500, 0.0200],\n",
            "        [0.6700, 0.3100, 0.5600, 0.2400],\n",
            "        [0.5000, 0.3400, 0.1600, 0.0400],\n",
            "        [0.5600, 0.2700, 0.4200, 0.1300],\n",
            "        [0.5500, 0.2300, 0.4000, 0.1300],\n",
            "        [0.6000, 0.2900, 0.4500, 0.1500],\n",
            "        [0.5400, 0.3700, 0.1500, 0.0200],\n",
            "        [0.5300, 0.3700, 0.1500, 0.0200],\n",
            "        [0.6200, 0.2800, 0.4800, 0.1800],\n",
            "        [0.4700, 0.3200, 0.1300, 0.0200],\n",
            "        [0.6400, 0.2800, 0.5600, 0.2100],\n",
            "        [0.5600, 0.3000, 0.4100, 0.1300],\n",
            "        [0.6700, 0.3300, 0.5700, 0.2500],\n",
            "        [0.5100, 0.3500, 0.1400, 0.0300],\n",
            "        [0.6000, 0.3000, 0.4800, 0.1800],\n",
            "        [0.6400, 0.2900, 0.4300, 0.1300],\n",
            "        [0.5700, 0.2800, 0.4100, 0.1300],\n",
            "        [0.6300, 0.3400, 0.5600, 0.2400],\n",
            "        [0.6400, 0.2700, 0.5300, 0.1900],\n",
            "        [0.6500, 0.3000, 0.5200, 0.2000],\n",
            "        [0.7600, 0.3000, 0.6600, 0.2100],\n",
            "        [0.4500, 0.2300, 0.1300, 0.0300],\n",
            "        [0.5500, 0.3500, 0.1300, 0.0200],\n",
            "        [0.4900, 0.3000, 0.1400, 0.0200],\n",
            "        [0.5800, 0.2800, 0.5100, 0.2400],\n",
            "        [0.5400, 0.3000, 0.4500, 0.1500],\n",
            "        [0.5000, 0.3200, 0.1200, 0.0200],\n",
            "        [0.5700, 0.3800, 0.1700, 0.0300],\n",
            "        [0.5200, 0.3400, 0.1400, 0.0200],\n",
            "        [0.5900, 0.3200, 0.4800, 0.1800],\n",
            "        [0.6900, 0.3100, 0.5100, 0.2300],\n",
            "        [0.5500, 0.2400, 0.3800, 0.1100],\n",
            "        [0.5500, 0.4200, 0.1400, 0.0200],\n",
            "        [0.7900, 0.3800, 0.6400, 0.2000],\n",
            "        [0.5800, 0.2700, 0.4100, 0.1000],\n",
            "        [0.6700, 0.3100, 0.4700, 0.1500],\n",
            "        [0.4600, 0.3600, 0.1000, 0.0200],\n",
            "        [0.6700, 0.3300, 0.5700, 0.2100],\n",
            "        [0.5700, 0.2500, 0.5000, 0.2000],\n",
            "        [0.5100, 0.3800, 0.1600, 0.0200],\n",
            "        [0.6500, 0.3000, 0.5800, 0.2200]]) tensor([1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
            "        1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0.,\n",
            "        0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.,\n",
            "        0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
            "        0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
            "        1., 0., 0., 0., 0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separar os dados em treinamento e testes\n",
        "entrada_treinamento = entrada[0:120, :]\n",
        "saida_treinamento = saida[0:120]\n",
        "entrada_testes = entrada[120:150, :]\n",
        "saida_testes = saida[120:150]\n",
        "print(entrada_testes)\n",
        "print(saida_testes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZaa73CpqOLg",
        "outputId": "e8044d2c-4228-4a12-e75e-87229565b01b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5600, 0.3000, 0.4100, 0.1300],\n",
            "        [0.6700, 0.3300, 0.5700, 0.2500],\n",
            "        [0.5100, 0.3500, 0.1400, 0.0300],\n",
            "        [0.6000, 0.3000, 0.4800, 0.1800],\n",
            "        [0.6400, 0.2900, 0.4300, 0.1300],\n",
            "        [0.5700, 0.2800, 0.4100, 0.1300],\n",
            "        [0.6300, 0.3400, 0.5600, 0.2400],\n",
            "        [0.6400, 0.2700, 0.5300, 0.1900],\n",
            "        [0.6500, 0.3000, 0.5200, 0.2000],\n",
            "        [0.7600, 0.3000, 0.6600, 0.2100],\n",
            "        [0.4500, 0.2300, 0.1300, 0.0300],\n",
            "        [0.5500, 0.3500, 0.1300, 0.0200],\n",
            "        [0.4900, 0.3000, 0.1400, 0.0200],\n",
            "        [0.5800, 0.2800, 0.5100, 0.2400],\n",
            "        [0.5400, 0.3000, 0.4500, 0.1500],\n",
            "        [0.5000, 0.3200, 0.1200, 0.0200],\n",
            "        [0.5700, 0.3800, 0.1700, 0.0300],\n",
            "        [0.5200, 0.3400, 0.1400, 0.0200],\n",
            "        [0.5900, 0.3200, 0.4800, 0.1800],\n",
            "        [0.6900, 0.3100, 0.5100, 0.2300],\n",
            "        [0.5500, 0.2400, 0.3800, 0.1100],\n",
            "        [0.5500, 0.4200, 0.1400, 0.0200],\n",
            "        [0.7900, 0.3800, 0.6400, 0.2000],\n",
            "        [0.5800, 0.2700, 0.4100, 0.1000],\n",
            "        [0.6700, 0.3100, 0.4700, 0.1500],\n",
            "        [0.4600, 0.3600, 0.1000, 0.0200],\n",
            "        [0.6700, 0.3300, 0.5700, 0.2100],\n",
            "        [0.5700, 0.2500, 0.5000, 0.2000],\n",
            "        [0.5100, 0.3800, 0.1600, 0.0200],\n",
            "        [0.6500, 0.3000, 0.5800, 0.2200]])\n",
            "tensor([1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Montar o modelo para o treinamento\n",
        "print(entrada_treinamento.size())\n",
        "input_size = entrada_treinamento.size()[1]\n",
        "hidden_size = 10\n",
        "modelo = Net(input_size, hidden_size)\n",
        "print(modelo)\n",
        "\n",
        "# Configurações do modelo\n",
        "criterion = torch.nn.BCELoss() # Binary Cross Entropy\n",
        "criterion = torch.nn.MSELoss() # Mean Square Error\n",
        "optimizer = torch.optim.SGD(modelo.parameters(), lr = 0.9, momentum = 0.3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4uV264Mqg1A",
        "outputId": "2404b69c-b756-4bae-c38e-324cb2dff467"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([120, 4])\n",
            "Net(\n",
            "  (fc1): Linear(in_features=4, out_features=10, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (fc2): Linear(in_features=10, out_features=1, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Treinar o modelo\n",
        "\n",
        "epochs = 10001 # Quantidade de épocas de treinamento\n",
        "\n",
        "errors = [] # Criando um array vazio para guardar os erros de cada epoca\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  optimizer.zero_grad()\n",
        "  # Forward pass\n",
        "  y_pred = modelo(entrada_treinamento)\n",
        "  #Compute Loss\n",
        "  loss = criterion(y_pred.squeeze(), saida_treinamento)\n",
        "  errors.append(loss.item())\n",
        "  if epoch % 100 == 0:\n",
        "    print('Epoch {}: train loss: {}'.format(epoch, loss.item()))\n",
        "  #Backward pass\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giFUNi_6qnFx",
        "outputId": "9057d059-6d5b-4f6a-9992-3990e90b0bd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: train loss: 0.252724826335907\n",
            "Epoch 100: train loss: 0.21281173825263977\n",
            "Epoch 200: train loss: 0.18860238790512085\n",
            "Epoch 300: train loss: 0.15469267964363098\n",
            "Epoch 400: train loss: 0.11319084465503693\n",
            "Epoch 500: train loss: 0.07748878747224808\n",
            "Epoch 600: train loss: 0.05698390677571297\n",
            "Epoch 700: train loss: 0.04433685913681984\n",
            "Epoch 800: train loss: 0.035967450588941574\n",
            "Epoch 900: train loss: 0.030275125056505203\n",
            "Epoch 1000: train loss: 0.026323508471250534\n",
            "Epoch 1100: train loss: 0.023526541888713837\n",
            "Epoch 1200: train loss: 0.021503871306777\n",
            "Epoch 1300: train loss: 0.020005924627184868\n",
            "Epoch 1400: train loss: 0.01886913552880287\n",
            "Epoch 1500: train loss: 0.017985830083489418\n",
            "Epoch 1600: train loss: 0.017283175140619278\n",
            "Epoch 1700: train loss: 0.01671277917921543\n",
            "Epoch 1800: train loss: 0.016241390258073807\n",
            "Epoch 1900: train loss: 0.015845591202378273\n",
            "Epoch 2000: train loss: 0.015508548356592655\n",
            "Epoch 2100: train loss: 0.015217852778732777\n",
            "Epoch 2200: train loss: 0.014964353293180466\n",
            "Epoch 2300: train loss: 0.014741083607077599\n",
            "Epoch 2400: train loss: 0.01454237475991249\n",
            "Epoch 2500: train loss: 0.014360915869474411\n",
            "Epoch 2600: train loss: 0.014195923693478107\n",
            "Epoch 2700: train loss: 0.014046926982700825\n",
            "Epoch 2800: train loss: 0.013911533169448376\n",
            "Epoch 2900: train loss: 0.013790830969810486\n",
            "Epoch 3000: train loss: 0.013680333271622658\n",
            "Epoch 3100: train loss: 0.013578171841800213\n",
            "Epoch 3200: train loss: 0.013483371585607529\n",
            "Epoch 3300: train loss: 0.013395082205533981\n",
            "Epoch 3400: train loss: 0.013312588445842266\n",
            "Epoch 3500: train loss: 0.013235271908342838\n",
            "Epoch 3600: train loss: 0.013162611052393913\n",
            "Epoch 3700: train loss: 0.013094143010675907\n",
            "Epoch 3800: train loss: 0.013029465451836586\n",
            "Epoch 3900: train loss: 0.012968232855200768\n",
            "Epoch 4000: train loss: 0.012910137884318829\n",
            "Epoch 4100: train loss: 0.012854879721999168\n",
            "Epoch 4200: train loss: 0.012802241370081902\n",
            "Epoch 4300: train loss: 0.012751992791891098\n",
            "Epoch 4400: train loss: 0.012703949585556984\n",
            "Epoch 4500: train loss: 0.012657912448048592\n",
            "Epoch 4600: train loss: 0.012613733299076557\n",
            "Epoch 4700: train loss: 0.01257125660777092\n",
            "Epoch 4800: train loss: 0.012530351988971233\n",
            "Epoch 4900: train loss: 0.012490902096033096\n",
            "Epoch 5000: train loss: 0.012452804483473301\n",
            "Epoch 5100: train loss: 0.012415946461260319\n",
            "Epoch 5200: train loss: 0.012380233965814114\n",
            "Epoch 5300: train loss: 0.012345598079264164\n",
            "Epoch 5400: train loss: 0.012311947531998158\n",
            "Epoch 5500: train loss: 0.012279214337468147\n",
            "Epoch 5600: train loss: 0.012247337959706783\n",
            "Epoch 5700: train loss: 0.012216239236295223\n",
            "Epoch 5800: train loss: 0.012185881845653057\n",
            "Epoch 5900: train loss: 0.012156207114458084\n",
            "Epoch 6000: train loss: 0.012127154506742954\n",
            "Epoch 6100: train loss: 0.012098697945475578\n",
            "Epoch 6200: train loss: 0.012070789001882076\n",
            "Epoch 6300: train loss: 0.012043377384543419\n",
            "Epoch 6400: train loss: 0.01201644353568554\n",
            "Epoch 6500: train loss: 0.01198994554579258\n",
            "Epoch 6600: train loss: 0.01196384523063898\n",
            "Epoch 6700: train loss: 0.011938133276998997\n",
            "Epoch 6800: train loss: 0.011912764981389046\n",
            "Epoch 6900: train loss: 0.01188772264868021\n",
            "Epoch 7000: train loss: 0.0118629802018404\n",
            "Epoch 7100: train loss: 0.011838514357805252\n",
            "Epoch 7200: train loss: 0.01181431207805872\n",
            "Epoch 7300: train loss: 0.011790349148213863\n",
            "Epoch 7400: train loss: 0.011766606010496616\n",
            "Epoch 7500: train loss: 0.011743063107132912\n",
            "Epoch 7600: train loss: 0.011719722300767899\n",
            "Epoch 7700: train loss: 0.011696561239659786\n",
            "Epoch 7800: train loss: 0.011673553846776485\n",
            "Epoch 7900: train loss: 0.011650711297988892\n",
            "Epoch 8000: train loss: 0.011628013104200363\n",
            "Epoch 8100: train loss: 0.011605446226894855\n",
            "Epoch 8200: train loss: 0.011583001352846622\n",
            "Epoch 8300: train loss: 0.01156066544353962\n",
            "Epoch 8400: train loss: 0.011538450606167316\n",
            "Epoch 8500: train loss: 0.011516326107084751\n",
            "Epoch 8600: train loss: 0.011494305916130543\n",
            "Epoch 8700: train loss: 0.011472365818917751\n",
            "Epoch 8800: train loss: 0.011450513266026974\n",
            "Epoch 8900: train loss: 0.011428739875555038\n",
            "Epoch 9000: train loss: 0.011407043784856796\n",
            "Epoch 9100: train loss: 0.011385411955416203\n",
            "Epoch 9200: train loss: 0.011363857425749302\n",
            "Epoch 9300: train loss: 0.011342366226017475\n",
            "Epoch 9400: train loss: 0.011320946738123894\n",
            "Epoch 9500: train loss: 0.011299580335617065\n",
            "Epoch 9600: train loss: 0.011278285644948483\n",
            "Epoch 9700: train loss: 0.01125703938305378\n",
            "Epoch 9800: train loss: 0.011235872283577919\n",
            "Epoch 9900: train loss: 0.011214754544198513\n",
            "Epoch 10000: train loss: 0.011193708516657352\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teste = np.array([5.2,2.1,3.6,1.6])\n",
        "testetensor = torch.FloatTensor(teste)\n",
        "testetensor /= 10\n",
        "y_pred = modelo(testetensor)"
      ],
      "metadata": {
        "id": "DW9c8WiYlkog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rodar a rede com os dados de teste, os dados que a rede nunca viu\n",
        "#y_pred = modelo(entrada_testes)\n",
        "#print(y_pred) # valor previsto pela rede\n",
        "#print(saida_testes) # valor real"
      ],
      "metadata": {
        "id": "XNzsxwu1quIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "def plotcharts(errors):\n",
        "    errors = np.array(errors)\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    graf02 = plt.subplot(1, 2, 1) # nrows, ncols, index\n",
        "    graf02.set_title('Errors')\n",
        "    plt.plot(errors, '-')\n",
        "    plt.xlabel('Epochs')\n",
        "    graf03 = plt.subplot(1, 2, 2)\n",
        "    graf03.set_title('Tests')\n",
        "    a = plt.plot(saida_testes.numpy(), 'yo', label='Real')\n",
        "    plt.setp(a, markersize=10)\n",
        "    a = plt.plot(y_pred.detach().numpy(), 'b+', label='Predicted')\n",
        "    plt.setp(a, markersize=10)\n",
        "    plt.legend(loc=7)\n",
        "    plt.show()\n",
        "plotcharts(errors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "2y00-_Zwqz-g",
        "outputId": "e409c8ea-af74-484c-c8b7-15b1f74f6df9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}